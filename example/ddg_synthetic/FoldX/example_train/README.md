## Graphinity training: toy example

This is a toy example (100 data points each in train, validation, and test datasets) intended to make it easy to try out the Graphinity training code, and will not produce a model with strong predictive performance.

### Data
Download the parquet files from https://opig.stats.ox.ac.uk/data/downloads/affinity_dataset/Synthetic_FoldX_ddG-example_train-parquets.tar.gz (185 MB). Untarring will create a pdb_wt/ (83 MB) and pdb_mut/ (103 MB) directory. Place these in the example/ddg_synthetic/FoldX/example_train/data/ directory:

WT PDB parquets: example/ddg_synthetic/FoldX/example_train/data/pdb_wt/
Mutant PDB parquets: example/ddg_synthetic/FoldX/example_train/data/pdb_mut/

These parquet files correspond to the PDBs in the Synthetic_FoldX_ddG-example_{train/val/test}-w_paths.csv files. The data points (100 each in train, validation, and test) were randomly selected from the Synthetic\_FoldX\_ddG\_942723 dataset with a 90% CDR sequence identity train-validation-test cutoff.

The parquet files were generated by processing (atom typing) the input PDB files using src/ddg_regression/base/dataset.py. The parquet files have a smaller file size than the corresponding PDB files and training/inference is faster when starting with pre-processed files.

To note, the code is compatible with PDB (rather than parquet) inputs as well; no changes need to be made to the code or config.

### Training Graphinity

From the root directory of the repository, run:

With a GPU (recommended):
```
python3 src/ddg_regression/train.py -c example/ddg_synthetic/FoldX/example_train/configs/config-example_train-gpu.yaml
```

CPU only:
```
python3 src/ddg_regression/train.py -c example/ddg_synthetic/FoldX/example_train/configs/config-example_train.yaml
```

The training can be logged using Weights and Biases (wandb) by updating the config file.
